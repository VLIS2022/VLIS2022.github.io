<!doctype html>
<html lang="en">
  <head>
    <meta charset="UTF-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <title>DOT</title>
    <meta name="author" content="Hao Ai">
    <meta name="description" content="Project page of DOT paper, ICCV 2023">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <link rel="icon" type="image/png" href="eccv_logo.png">
    <!-- Format -->
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/css/bootstrap.min.css">
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.4.0/css/font-awesome.min.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.8.0/codemirror.min.css">
    <link rel="stylesheet" href="../format/app.css">
    <link rel="stylesheet" href="../format/bootstrap.min.css">
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.3/jquery.min.js"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/js/bootstrap.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.8.0/codemirror.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/1.5.3/clipboard.min.js"></script>
    <script src="../format/app.js"></script>

  </head>

  <body style=“text-align: center;”>
    <div class="container" id="main">
        <div class="row">
            <h1 class="col-md-12 text-center">
                Dynamic PlenOctree for Adaptive Sampling Refinement in Explicit NeRF<br /> 
<!--                 <small>
                    
                </small> -->
            </h1>
        </div>
        
        <div class="row">
            <div class="col-md-12 text-center">
                <ul class="list-inline">
                    <li>
			<img src="./image/haotianbai.jpg" height="80px"><br>
                        <a href="https://scholar.google.com/citations?hl=en&user=DIy4cA0AAAAJ" >
                         Haotian Bai
                        </a>
                        
                        <br /> AI Thrust, HKUST(GZ)
                        <br /> &nbsp &nbsp

                    </li>

                    <li>
			<img src="./image/yiqilin.jpg" height="80px"><br>
                        Yiqi Lin
                      </a>
                      <br /> AI Thrust, HKUST(GZ)
                      <br /> &nbsp &nbsp
                    </li>

                    <li>
			    <img src="./image/yizechen.jpg" height="80px"><br>
                        <a href="https://scholar.google.com/citations?user=G1NiRmwAAAAJ&hl=en" >
                           Yize chen
                        </a>
                        <br /> AI Thrust, HKUST(GZ) 
			            <br/> Dept. of CSE, HKUST 

                    </li>
                  
                    <li>
			    <img src="./image/linwang.jpg" height="80px"><br>
                        <a href="https://addisonwang2013.github.io/vlislab/linwang.html">
                           Addison Lin Wang
                        </a>
                        <br /> AI Thrust, HKUST(GZ) 
			    <br/> Dept. of CSE, HKUST 
                    </li>
                </ul>
            </div>
        </div>



        <!-- ##### Elements #####-->
        <div class="row">
                <div class="col-md-8 col-md-offset-2 text-center">
                    <ul class="nav nav-pills nav-justified">
                        <li>
			 <!-- <a href="https://arxiv.org/abs/2303.11616"> -->
                            <img src="./image/arxiv.png" height="100px"><br>
                                <h4><strong>Paper</strong></h4>
                            </a>
                        </li>
                        <li>

                            <img src="./image/youtube_icon.jpg" height="100px"><br>
                                <h4><strong>Video</strong></h4>
                            </a>
                        </li>
                        <li>
                            <a href="https://github.com/164140757/DOT">
                            <img src="./image/github_icon.jpg" height="100px"><br>
                                <h4><strong>Code</strong></h4>
                            </a>
                        </li>

                        <!-- <li>
                            
                            <img src="./image/colab_icon.jpg" height="100px"><br>
                                <h4><strong>Colab</strong></h4>
                            </a>
                        </li> -->
 

                        <li>
                            <!-- <a href="https://github.com/haoai-1997/haoai-1997.github.io/blob/main/HRDFuse/CVPR2023_HRDFuse_supp.pdf"> -->
                            <img src="./image/slide_icon.jpg" height="100px"><br>
                                <h4><strong>Supp</strong></h4>
                            </a>
                        </li>                     
                        <li>
                            <a href="https://addisonwang2013.github.io/vlislab/index.html">
                            <img src="./image/lab_logo.png" height="100px"><br>
                                <h4><strong>Vlislab</strong></h4>
                            </a>
                        </li>                       
                      
                    </ul>
                </div>
        </div>


        <!-- ##### Abstract #####-->
        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Abstract
                </h3>
                <p class="text-justify">
                    The explicit neural radiance field (NeRF) has gained considerable interest for its efficient training and fast inference capabilities, making it a promising direction such as virtual reality and gaming. In particular, PlenOctree (POT) [1], an explicit hierarchical multi-scale octree representation, has emerged as a structural and influential framework. However, POT’s fixed structure for direct optimization is sub-optimal as the scene complexity evolves continuously with updates to cached color and density, necessitating refining the sampling distribution to capture signal complexity accordingly. To address this issue, we propose the dynamic PlenOctree (DOT), which adaptively refines the sample distribution to adjust to changing scene complexity. Specifically, DOT proposes a concise yet novel hierarchical feature fusion strategy during the iterative rendering process. Firstly, it identifies the regions of interest through training signals to ensure adaptive and efficient refinement. Next, rather than directly filtering out valueless nodes, DOT introduces the sampling and pruning operations for octrees to aggregate features, enabling rapid parameter learning. Compared with POT, our DOT outperforms it by enhancing visual quality, 
                    reducing over <b>55.15/68.84%</b> parameters, 
                    and providing <b>1.7/1.9</b> times FPS for NeRF-synthetic and Tanks & Temples, respectively.
                </p>
            </div>
        </div>

 

        <!-- ##### Results #####-->

     <div class="row">     
        <div class="col-md-8 col-md-offset-2">
            <h3>
                Inspiration
            </h3>
            <p class="text-justify">
                While the POT framework is effective, its fixed octree structure can limit its adaptability to varying scene complexities.
                 We introduce hierarchical feature fusion with sampling/pruning to overcome this limitation, as illustrated by the dashed box below. 
                 Varying colors on the grid represent the training signals. 
                 Internal nodes are denoted in <span style="color:orange">orange</span>, 
                 while leaf nodes in <span style="color:green">orange</span>. Pruning occurs in regions of weak signal, 
                 where cached properties in leaf nodes are aggregated, and the averaged value is propagated to internal nodes, 
                 which become the new leaves. Complementary sampling takes place in the red regions. 
                 The resulting sampling distribution exhibits significant improvement, as highlighted by the red boxes in our final octree results.
            </p>
            <img src="./image/teaser.png" class="img-responsive" alt="vis_res"  class="center" >
      </div>           
     <div class="col-md-8 col-md-offset-2">
          <h3>
              Comparison on octree representations
          </h3>
          <p class="text-justify">
            DOT shows the more compact structure of DOT, 
            resulting in fewer ray intersections, explaining our significant rendering speed boost.

          </p>
		  <img src="./image/dot_cp.png" class="img-responsive" alt="vis_res" class="center"><br>
    </div>   
    <div class="col-md-8 col-md-offset-2">
        <h3>
            Comparison on visual quality and memory consumption
        </h3>
        <p class="text-justify">
            DOT provides more details in complex regions, such as sharper reflections on windows and more evident edges on fences. 

        </p>
        <img src="./image/dot_cp2.png" class="img-responsive" alt="vis_res" class="center"><br>
    </div>     
    </div>


		      
    	<div class="row">      
     <div class="col-md-8 col-md-offset-2">
          <h3>
              Demo 
          </h3>   
    </div>   
      
    <div class="col-md-8 col-md-offset-2">

            <video width="800"  controls >
                <source src="./video/dot.mp4" type="video/mp4">
              Your browser does not support HTML video.
            </video>   
    </div>          
      </div>
   <!-- ##### BibTex #####-->
        <hr>
        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    BibTeX
                </h3>
 
                <div class="row align-items-center">
                    <div class="col py-3">
                        <pre class="border">             
@inproceedings{Bai2023DOT,
  title={Dynamic PlenOctree for Adaptive Sampling Refinement in Explicit NeRF},
  author={Haotian Bai, Yiqi Lin, Yize Chen, Lin Wang},
  booktitle = {IEEE International Conference on Computer Vision (ICCV)},
  year={2023}
}
</pre>
                    </div>
                </div>
              
    
          </div>
          
        </div>
    </div>
</body>
</html>
