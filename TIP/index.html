<!doctype html>
<html lang="en">
  <head>
    <meta charset="UTF-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <title>HRDFuse</title>
    <meta name="author" content="Zidong Cao">
    <meta name="description" content="Project page of 360SSKT paper, 2023">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <link rel="icon" type="image/png" href="eccv_logo.png">
    <!-- Format -->
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/css/bootstrap.min.css">
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.4.0/css/font-awesome.min.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.8.0/codemirror.min.css">
    <link rel="stylesheet" href="../format/app.css">
    <link rel="stylesheet" href="../format/bootstrap.min.css">
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.3/jquery.min.js"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/js/bootstrap.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.8.0/codemirror.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/1.5.3/clipboard.min.js"></script>
    <script src="../format/app.js"></script>

  </head>

  <body style=“text-align: center;”>
    <div class="container" id="main">
        <div class="row">
            <h1 class="col-md-12 text-center">
               360$^\circ$ High-Resolution Depth Estimation via Uncertainty-aware Structural Knowledge Transfer  <br /> 
         
<!--                 <small>
                    
                </small> -->
            </h1>
        </div>
        
        <div class="row">
            <div class="col-md-12 text-center">
                <ul class="list-inline">
                    <li>
			<img src="./image/zidongcao.jpeg" height="80px"><br>
                         Zidong Cao
                        </a>
                        <br /> AI Thrust, HKUST(GZ)
                        <br /> &nbsp &nbsp
                    </li>

                    <li>
			<img src="./image/haoai.jpeg" height="80px"><br>
			<a href="https://haoai-1997.github.io/" >
                        Hao Ai
                      </a>
                        <br /> AI Thrust, HKUST(GZ)
                      <br /> &nbsp &nbsp
                    </li>
                  
                    <li>
			    <img src="./image/linwang.jpeg" height="80px"><br>
                        <a href="https://addisonwang2013.github.io/vlislab/linwang.html">
                           Addison Lin Wang
                        </a>
                        <br /> AI Thrust, HKUST(GZ) 
			    <br/> Dept. of CSE, HKUST 
                    </li>
                </ul>
            </div>
        </div>



        <!-- ##### Elements #####-->
        <div class="row">
                <div class="col-md-8 col-md-offset-2 text-center">
                    <ul class="nav nav-pills nav-justified">
                        <li>
			 <a href="https://arxiv.org/abs/2303.11616">
                            <img src="./paper.png" height="100px"><br>
                                <h4><strong>Paper</strong></h4>
                            </a>
                        </li>
                        <li>

                            <img src="./image/youtube_icon.jpeg" height="100px"><br>
                                <h4><strong>Video</strong></h4>
                            </a>
                        </li>
                        <li>
                            <a href="https://github.com/haoai-1997/HRDFuse">
                            <img src="./image/github_icon.jpeg" height="100px"><br>
                                <h4><strong>Code</strong></h4>
                            </a>
                        </li>

                        <li>
                            
                            <img src="./image/colab_icon.jpeg" height="100px"><br>
                                <h4><strong>Colab</strong></h4>
                            </a>
                        </li>
 

                        <li>
                            <a href="https://github.com/haoai-1997/haoai-1997.github.io/blob/main/HRDFuse/CVPR2023_HRDFuse_supp.pdf">
                            <img src="./image/slide_icon.jpeg" height="100px"><br>
                                <h4><strong>Supp</strong></h4>
                            </a>
                        </li>                     
                      
                      
                    </ul>
                </div>
        </div>


        <!-- ##### Abstract #####-->
        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Abstract
                </h3>
                <p class="text-justify">
               Recently, omnidirectional images (ODIs) have become increasingly popular; however, their angular resolution tends to be lower than that of perspective images. This leads to degraded structural details such as edges, causing difficulty in learning 3D scene understanding tasks, especially monocular depth estimation. Existing methods typically leverage high-resolution (HR) ODI as the input, so as to recover the structural details via fully-supervised learning. However, the HR depth ground truth (GT) maps may be arduous or expensive to be collected due to resource-constrained devices in practice. Therefore, in this paper, we explore for the first time to estimate the HR omnidirectional depth directly from a low-resolution (LR) ODI, when no HR depth GT map is available. Our key idea is to transfer the scene structural knowledge from the readily available HR image modality and the corresponding LR depth maps to achieve the goal of HR depth estimation without extra inference cost. Specifically, we introduce ODI super-resolution (SR) as an auxiliary task and train both tasks collaboratively in a weakly supervised manner to boost the performance of HR depth estimation. The ODI SR task takes an LR ODI as the input to predict an HR image, enabling us to extract the scene structural knowledge via uncertainty estimation. Buttressed by this, a scene structural knowledge transfer (SSKT) module is proposed with two key components. First, we employ a cylindrical implicit interpolation function (CIIF) to learn cylindrical neural interpolation weights for feature up-sampling and share the parameters of CIIFs between the two tasks. Then, we propose a feature distillation (FD) loss that provides extra structural regularization to help the HR depth estimation task learn more scene structural knowledge. Extensive experiments demonstrate that our weakly-supervised method outperforms baseline methods, and even achieves comparable performance with the fully-supervised methods.
                </p>
            </div>
        </div>

 

        <!-- ##### Results #####-->
   
     <div class="row">     
       
     <div class="col-md-8 col-md-offset-2">
          <h3>
              Results on the benchmarkdataset: Stanford2D3D, Matterport3D and 3D60
          </h3>
		  <img src="./visual_results.png" class="img-responsive" alt="vis_res" class="center"><br>
    </div>     
      </div>

        <!-- ##### Approach #####-->
        <div class="row">
          <div class="col-md-8 col-md-offset-2">
              <h3>
                Approach 
              </h3>
              <p class="text-justify">
             The goal is to predict an HR omnidirectional depth map $D_{\mathrm{HR}}$ from an LR ODI $I_{\mathrm{LR}}$ as input, using only an LR depth map $D^{\mathrm{GT}}_{\mathrm{LR}}$ for supervision. As shown in Fig.~\ref{fig:framework}, our framework consists of an ODI SR task, a scene structural knowledge transfer (SSKT) module, and an HR depth estimation task. The ODI SR is employed as an auxiliary task and trained collaboratively with the HR depth estimation task. Specifically, we introduce uncertainty estimation to the ODI SR task for scene structural knowledge extraction. To transfer the extracted knowledge, the SSKT module is proposed with two components. The first is to share the parameters of the proposed cylindrical implicit interpolation function (CIIF) between the two tasks. The second is the feature distillation (FD) loss that provides extra structural regularization. 
              </p>
		      
            <img src="./framework.png" class="img-responsive" alt="method" class="center"><br>

          </div>
        </div>             
      </div>
   <!-- ##### BibTex #####-->
        <hr>
        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    BibTeX
                </h3>
 
                <div class="row align-items-center">
                    <div class="col py-3">
                        <pre class="border">             
@inproceedings{arxiv,
  title={360$^\circ$ High-Resolution Depth Estimation via Uncertainty-aware Structural Knowledge Transfer},
  author={Zidong Cao, Hao Ai, Lin Wang},
  booktitle = {Arxiv},
  year={2023}
}
</pre>
                    </div>
                </div>
              
    
          </div>
          
        </div>
    </div>
</body>
</html>
