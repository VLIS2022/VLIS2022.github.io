<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<link rel="shortcut icon" href="favicon.ico" />
<link rel="bookmark" href="favicon.ico" type="image/x-icon"ã€€/>
<title>Hao Ai (Hobby)</title>
</head>
<body>
<table summary="Table for page layout." id="tlayout">
<tr valign="top">
<td id="layout-menu">
<div class="menu-category">Menu</div>
<div class="menu-item"><a href="index.html" class="current">Home</a></div>
<div class="menu-item"><a href="https://scholar.google.com/citations?user=QNlF0DsAAAAJ&hl=zh-CN">Google Scholar</a></div>
<div class="menu-item"><a href="https://github.com/haoai-1997">GitHub</a></div>
</td>
<td id="layout-content">
<div id="toptitle">
<h1>Hao Ai (Hobby) </h1>
</div>
<table class="imgtable"><tr><td>
<a href="https://haoai-1997.github.io/"><img src="photos/bio.jpg" alt="alt text" width="160px" height="160px" /></a>&nbsp;</td>
<td align="left"><p>PhD student,<br />
AI Trust<br />
Information Hub <br />
HKUST(GZ) <br />
E-mail: <a href="">aihao199712@gmail.com</a></p>
</td></tr></table>
<h2>About me</h2>
<p>I received the B.S. degree of EE from the Beijing Jiaotong University(<a href="http://en.njtu.edu.cn/">BJTU</a>), in 2018, and the M.S. degree of EE from Tsinghua University (<a href="https://www.ee.tsinghua.edu.cn/">THU</a>), advised by <a href="https://www.sigs.tsinghua.edu.cn/lqm/main.htm">Qingmin Liao </a>, in 2022. Now I am currently a first-year PhD student of <a href="https://addisonwang2013.github.io/vlislab/people">VLISLAB</a>, advised by <a href="https://addisonwang2013.github.io/vlislab/linwang.html"> Addison Lin Wang </a>.  I am currently a research intern at Tencent ARC lab. 
<br> I'm interested in novel camera system, pattern recognition, and image generation.</p>
<h2>Research</h2>
<p>My research interests include: </p>
<ul>
<li><p>DL-based Omnidirectional Vision, especially for scene understanding</p>
</li>
<li><p>pattern recognition, e.g., image classification, face recognition.</p>
</li>
<li><p>AI-based content generation</p>
</li>
</ul>
<h2>News</h2>
<ul>
<li><p>News (Fed  2023): One papers accepted to CVPR 2023.</p>
</li>
<li><p>News (May  2022): The first survey aboout DL-based Omnidirectional vision submitted to TPAMI.</p>
</li>
</ul>
<h2>Publications</h2><p> (* indicates joint first authors) </p>
<ul>
<li><p style="color:red">HRDFuse: Monocular 360&deg; Depth Estimation by Collaboratively Learning Holistic-with-Regional Depth Distributions</p>
</li>
<strong>  Hao Ai </strong>, Zidong Cao, Yan-pei Cao, Ying Shan, Lin Wang
<br>
<em> CVPR</em>, 2023   
<br>
<a href="https://arxiv.org/abs/2212.06135">arxiv</a> / 
<a href="https://3d-avatar-diffusion.microsoft.com/">code</a> /  
<a href="https://haoai-1997.github.io/HRDFuse/">project website</a> /  
<a href="https://www.youtube.com/watch?v=KW_EXWMjS4c">video</a> /
<p style="color:blue"> In this paper, we propose a novel framework, <b>HRDFuse</b>, that subtly combines the potential of convolutional neural networks (CNNs) and transformers by collaboratively learning the <i>holistic</i> contextual information from the ERP and the <i>regional</i> structural information from the TP.
</p>
</ul>
<ul>
<li><p style="color:red">Deep Learning for Omnidirectional Vision: A Survey and New Perspectives</p>
</li>
<strong>  Hao Ai* </strong>, Zidong Cao*, Jinjing Zhu, Haotian Bai, Yucheng Chen, Ling Wang
<br>
<em> Arxiv</em>, 2022   
<br>
<a href="https://arxiv.org/abs/2212.06135">arxiv</a> / 
<a href="https://3d-avatar-diffusion.microsoft.com/">project website</a> /  
<p style="color:blue"> This paper presents a systematic and comprehensive review and analysis of the recent progress in <b>DL methods for omnidirectional vision</b>.
</p>
</ul>
<ul>
<li><p style="color:red">Gaussian Mixture Distribution Makes Data Uncertainty Learning Better</p>
</li>
<strong>  Hao Ai </strong>, Y Chen, J Qian, Q Liao
<br>
<em> Automatic Face and Gesture Recognition (FG)</em>, 2021   
<br>
<a href="https://ieeexplore.ieee.org/abstract/document/9666964">paper</a> / 
<a href="https://3d-avatar-diffusion.microsoft.com/">Poster</a> /  
<p style="color:blue">  In this paper, we propose a novel <b>uncertainty-based face recognition framework</b> based on the multivariate Gaussian mixture distribution (DUL-GM).
</p>
</ul>

<table style="width:80%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:center;font-size:medium ;">Thanks to <a href="https://jonbarron.info/"> Jon Barron</a> and <a href="http://zhouxiuze.com/"> Xiuze Zhou</a> for sharing the code of his personal webpage.</p>
              </p>
            </td>
          </tr>
        </tbody></table>

</td>
</tr>
</table>
</body>
</html>
