<!doctype html>
<html lang="en">
  <head>
    <meta charset="UTF-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <title>HRDFuse</title>
    <meta name="author" content="Zidong Cao">
    <meta name="description" content="Project page of 360SSKT paper, 2023">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <link rel="icon" type="image/png" href="eccv_logo.png">
    <!-- Format -->
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/css/bootstrap.min.css">
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.4.0/css/font-awesome.min.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.8.0/codemirror.min.css">
    <link rel="stylesheet" href="../format/app.css">
    <link rel="stylesheet" href="../format/bootstrap.min.css">
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.3/jquery.min.js"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/js/bootstrap.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.8.0/codemirror.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/1.5.3/clipboard.min.js"></script>
    <script src="../format/app.js"></script>

  </head>

  <body style=“text-align: center;”>
    <div class="container" id="main">
        <div class="row">
            <h1 class="col-md-12 text-center">
               360$^\circ$ High-Resolution Depth Estimation via Uncertainty-aware Structural Knowledge Transfer  <br /> 
         
<!--                 <small>
                    
                </small> -->
            </h1>
        </div>
        
        <div class="row">
            <div class="col-md-12 text-center">
                <ul class="list-inline">
                    <li>
			<img src="./image/zidongcao.jpg" height="80px"><br>
                        <a href="https://haoai-1997.github.io/" >
                         Zidong Cao
                        </a>
                        <br /> AI Thrust, HKUST(GZ)
                        <br /> &nbsp &nbsp
                    </li>

                    <li>
			<img src="./image/haoai.jpg" height="80px"><br>
                        Hao Ai
                      </a>
                        <br /> AI Thrust, HKUST(GZ)
                      <br /> &nbsp &nbsp
                    </li>
                  
                    <li>
			    <img src="./image/linwang.jpg" height="80px"><br>
                        <a href="https://addisonwang2013.github.io/vlislab/linwang.html">
                           Addison Lin Wang
                        </a>
                        <br /> AI Thrust, HKUST(GZ) 
			    <br/> Dept. of CSE, HKUST 
                    </li>
                </ul>
            </div>
        </div>



        <!-- ##### Elements #####-->
        <div class="row">
                <div class="col-md-8 col-md-offset-2 text-center">
                    <ul class="nav nav-pills nav-justified">
                        <li>
			 <a href="https://arxiv.org/abs/2303.11616">
                            <img src="./paper.png" height="100px"><br>
                                <h4><strong>Paper</strong></h4>
                            </a>
                        </li>
                        <li>

                            <img src="./image/youtube_icon.jpg" height="100px"><br>
                                <h4><strong>Video</strong></h4>
                            </a>
                        </li>
                        <li>
                            <a href="https://github.com/haoai-1997/HRDFuse">
                            <img src="./image/github_icon.jpg" height="100px"><br>
                                <h4><strong>Code</strong></h4>
                            </a>
                        </li>

                        <li>
                            
                            <img src="./image/colab_icon.jpg" height="100px"><br>
                                <h4><strong>Colab</strong></h4>
                            </a>
                        </li>
 

                        <li>
                            <a href="https://github.com/haoai-1997/haoai-1997.github.io/blob/main/HRDFuse/CVPR2023_HRDFuse_supp.pdf">
                            <img src="./image/slide_icon.jpg" height="100px"><br>
                                <h4><strong>Supp</strong></h4>
                            </a>
                        </li>                     
                      
                      
                    </ul>
                </div>
        </div>


        <!-- ##### Abstract #####-->
        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Abstract
                </h3>
                <p class="text-justify">
               Recently, omnidirectional images (ODIs) have become increasingly popular; however, their angular resolution tends to be lower than that of perspective images. This leads to degraded structural details such as edges, causing difficulty in learning 3D scene understanding tasks, especially monocular depth estimation. Existing methods typically leverage high-resolution (HR) ODI as the input, so as to recover the structural details via fully-supervised learning. However, the HR depth ground truth (GT) maps may be arduous or expensive to be collected due to resource-constrained devices in practice. Therefore, in this paper, we explore for the first time to estimate the HR omnidirectional depth directly from a low-resolution (LR) ODI, when no HR depth GT map is available. Our key idea is to transfer the scene structural knowledge from the readily available HR image modality and the corresponding LR depth maps to achieve the goal of HR depth estimation without extra inference cost. Specifically, we introduce ODI super-resolution (SR) as an auxiliary task and train both tasks collaboratively in a weakly supervised manner to boost the performance of HR depth estimation. The ODI SR task takes an LR ODI as the input to predict an HR image, enabling us to extract the scene structural knowledge via uncertainty estimation. Buttressed by this, a scene structural knowledge transfer (SSKT) module is proposed with two key components. First, we employ a cylindrical implicit interpolation function (CIIF) to learn cylindrical neural interpolation weights for feature up-sampling and share the parameters of CIIFs between the two tasks. Then, we propose a feature distillation (FD) loss that provides extra structural regularization to help the HR depth estimation task learn more scene structural knowledge. Extensive experiments demonstrate that our weakly-supervised method outperforms baseline methods, and even achieves comparable performance with the fully-supervised methods.
                </p>
            </div>
        </div>

 

        <!-- ##### Results #####-->
   
     <div class="row">     
       
     <div class="col-md-8 col-md-offset-2">
          <h3>
              Results on the benchmarkdataset: Stanford2D3D, Matterport3D and 3D60
          </h3>
		  <img src="./visual_results.png" class="img-responsive" alt="vis_res" class="center"><br>
    </div>     
      </div>

        <!-- ##### Approach #####-->
        <div class="row">
          <div class="col-md-8 col-md-offset-2">
              <h3>
                Approach 
              </h3>
              <p class="text-justify">
             Overview of our HRDFuse, consisting of three parts: feature extractors for both ERP and TP inputs, spatial feature alignment (SFA) module, 
             and collaborative depth distribution classification (CDDC) module. 
		      <br>
	     As depicted in the framework figure, to exploit the complementary information from holistic context and regional structure, our framework simultaneously takes two projections of a 360&deg; image, an ERP image and <i>N</i> TP patches, as inputs. For the ERP branch, an ERP image with the resolution of <i>H x W</i> is fed into a feature extractor, comprised of an encoder-decoder block, to produce a decoded ERP feature map <b>F<sup>ERP</sup></b>. For the TP branch, <i>N</i> TP patches are first obtained with gnomonic projection from the same sphere. Then, these TP patches are passed through the TP feature extractor to obtain 1-D patch feature vectors {V<sub>n</sub>, n=1,..., N}, which are passed through the TP decoder to obtain the TP feature maps {<b>F<sub>n</sub><sup>TP</sup></b>}. 

To determine and align the spatial location of each TP patch in the ERP space and avoid complex geometric fusion for overlapping areas between neighboring TP patches, we propose the spatial feature alignment (SFA) module to learn feature correspondences between pixel vectors in the ERP feature map <b>F<sup>ERP</sup></b> and patch feature vectors {V<sub>n</sub>, n=1,..., N}. This way, we can obtain the spatially aligned index map <b>M</b>, recording the location of each patch in the ERP space.

Next, the index map <b>M</b>, ERP feature map <b>F<sup>ERP</sup></b>, and TP feature maps <b>F<sub>n</sub><sup>TP</sup></b> are fed into the proposed collaborative depth distribution classification (CDDC) module that accordingly outputs two ERP format depth predictions. In principle, the CDDC module first learns holistic-with-regional histograms to simultaneously capture depth distributions from the ERP image and a set of TP patches. Consequently, the depth distributions are then converted to depth values through a linear combination of bin centers. Lastly, the two depth predictions from the CDDC module are adaptively fused to output the final depth result. We now describe these modules in detail.
              </p>
		      
            <img src="./sfa-v6.png" class="img-responsive" alt="method" class="center"><br>

          </div>
        </div>
    
    
         <div class="row">
          <div class="col-md-8 col-md-offset-2">
                <h3>
                    Results on Real Data
                </h3>   
            
          <img src="./real_data.png" class="img-responsive" alt="real" class="center"><br>
           
          </div>
        </div>
		      
    	<div class="row">      
     <div class="col-md-8 col-md-offset-2">
          <h3>
              Demo with Our HRDFuse
          </h3>   
    </div>   
      
    <div class="col-md-8 col-md-offset-2">

            <video width="800"  controls >
                <source src="./video/1.mp4" type="video/mp4">
              Your browser does not support HTML video.
            </video>   
    </div>          
      </div>
   <!-- ##### BibTex #####-->
        <hr>
        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    BibTeX
                </h3>
 
                <div class="row align-items-center">
                    <div class="col py-3">
                        <pre class="border">             
@inproceedings{arxiv,
  title={360$^\circ$ High-Resolution Depth Estimation via Uncertainty-aware Structural Knowledge Transfer},
  author={Zidong Cao, Hao Ai, Lin Wang},
  booktitle = {Arxiv},
  year={2023}
}
</pre>
                    </div>
                </div>
              
    
          </div>
          
        </div>
    </div>
</body>
</html>
