<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8">
    <meta name="description" content="FMapping">
    <meta name="keywords" content="fmap">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>FMapping: Factorized Efficient Neural Field Mapping for Real-Time Dense RGB SLAM</title>
 
    <script>
      window.dataLayer = window.dataLayer || [];
      
      function gtag() {
      dataLayer.push(arguments);
      }

      gtag('js', new Date());

      gtag('config', 'G-PYVRSFMDRL');
    </script>

    <link rel="stylesheet" href="./static/css/bulma.min.css">
    <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
    <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
    <link rel="stylesheet" href="./static/font-awesome-4.7.0/css/font-awesome.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
    <link rel="stylesheet" href="./static/css/index.css">
    <link rel="stylesheet" type="text/css" href="./static/css/magnifier.css">
    
  </head>

  <body>

    <section class="hero">
      <div class="hero-body">
        <div class="container">
          <div class="columns is-centered">
            <div class="column has-text-centered">
              <h1 class="title is-2 publication-title">FMapping: Factorized Efficient Neural Field Mapping for Real-Time Dense RGB SLAM</h1>

                            <div class="is-size-5 publication-authors">

                <span class="author-block">
                  <!--<a href="https://mohammadjohari.github.io/"> Mohammad Mahdi Johari</a> <sup>1,2</sup>, <a href="https://ch.linkedin.com/in/camilla-carta"> Camilla Carta </a><sup>3</sup>, <a href="https://fleuret.org/francois/"> Fran√ßois Fleuret </a><sup>4,2,1</sup> </span> -->
                  Tongyan Hua </a> <sup>1</sup>, 
                  Haotian Bai </a><sup>1</sup>, 
                  Zidong Cao </a><sup>1</sup>,
                  Addison Lin Wang </a><sup>1,2</sup>  
                </span>

                <div class="is-size-5 publication-authors">
                  <span class="author-block"><sup>1</sup> AI Thrust, HKUST(GZ) &nbsp;&nbsp;</span>
                  <span class="author-block"><sup>2</sup> Dept. of CSE, HKUST &nbsp;&nbsp;</span>
                </div>

                <br>
                <div class="column has-text-centered">
                  <div class="publication-links">

                    <!-- <\!-- PDF -\-> -->
                    <!--  <span class="link-block">
                       <a href="https://publidiap.idiap.ch/attachments/papers/2023/Johari_CVPR_2023.pdf"
                          class="external-link button is-normal is-rounded is-dark">
                         <span class="icon">
                           <i class="fa fa-file-pdf-o"></i>
                         </span>
                         <span>Paper</span>
                       </a>
                     </span>  -->

                    <!-- <\!-- ArXiv -\->               -->
                    <span class="link-block">
                      <a href="https://arxiv.org/abs/2211.11704"
                         class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="ai ai-arxiv"></i>
                        </span>
                        <span>arXiv</span>
                      </a>
                    </span>

                    <!-- <\!-- supplementary PDF -\-> -->
                    <!-- <span class="link-block"> -->
                    <!--   <a href="include/supp.pdf" -->
                    <!--      class="external-link button is-normal is-rounded is-dark"> -->
                    <!--     <span class="icon"> -->
                    <!--       <i class="fas fa-file-pdf"></i> -->
                    <!--     </span> -->
                    <!--     <span>Supplementary</span> -->
                    <!--   </a> -->
                    <!-- </span> -->

                    <!-- Video -->
<!--                    <span class="link-block">-->
<!--                      <a href="https://www.youtube.com/watch?v=-jNBsG3IP54"-->
<!--                         class="external-link button is-normal is-rounded is-dark">-->
<!--                        <span class="icon">-->
<!--                          <i class="fa fa-video-camera"></i>-->
<!--                        </span>-->
<!--                        <span>Video</span>-->
<!--                      </a>-->
<!--                    </span>-->

                    <!-- Code -->
                    <span class="link-block">
                      <a href="https://github.com/thua919/FMapping"
                         class="external-link button is-normal is-rounded is-dark">
                        <span class="icon"> -->
                          <i class="fa fa-github"></i>
                          </svg>
                        </span>
                        <span>Code</span>
                      </a>
                    </span>

                  </div>
                </div>
              </div>


              </div>
            </div>
          </div>
        </div>
    </section>


    <br>

    <section class="section">
      <div class="container">

        <!-- Abstract. -->
        <div class="columns is-centered has-text-centered">
          <div class="column is-two-thirds">
            <h2 class="title is-2">Abstract</h2>
            <div class="content has-text-justified">
              <p>
                In this paper, we introduce FMapping, an efficient neural field mapping framework that facilitates the continuous estimation of a colorized point cloud map in real-time dense RGB SLAM. To achieve this challenging goal without depth, a hurdle is how to improve efficiency and reduce the mapping uncertainty of the RGB SLAM system. 
                To this end, we first build up a theoretical analysis by decomposing the SLAM system into tracking and mapping parts, and the mapping uncertainty is explicitly defined within the frame of neural representations. Based on the analysis, we then propose an effective factorization scheme for scene representation and introduce a sliding window strategy to reduce the uncertainty for scene reconstruction. Specifically, we leverage the factorized neural field to decompose uncertainty into a lower-dimensional space, which enhances robustness to noise and improves training efficiency. 
                We then propose the sliding window sampler to reduce uncertainty  by incorporating coherent geometric cues from observed frames during map initialization to enhance convergence. 
                Our factorized neural mapping approach enjoys some advantages, such as low memory consumption, more efficient computation, and fast convergence during map initialization.
                Experiments on two benchmark datasets show that our method can update the map of high-fidelity colorized point clouds around 2 seconds in real time while requiring no customized CUDA kernels. Additionally, it utilizes x20 fewer parameters than the most concise neural implicit mapping of prior methods for SLAM, e.g., iMAP and around x1000 fewer parameters than the state-of-the-art approach, e.g., NICE-SLAM.              
              </p>
            </div>
          </div>
        </div>
      </div>

      <div class="container"> 
        <!--/ Overview. -->
        <div align="center" style="margin-top:80px;" style="margin-bottom:120px;">
          <img style='height: auto; width: 100%; object-fit: contain'
               src="framework.png" alt="overview_image">
        </div>
      </div>

    </section>

    <br>
    <br>
    <br>

    <section>
      <div class="container"> 
        <div class="columns is-centered"> 
          <div class="column is-full-width">
            <h2 align="center"  class="title is-2"> Results </h2>

            <h3 align="center"> Dense mapping snapshots (at 100, 400, and 1800 input frames) of the on-the-fly running of NICE-SLAM(-), iMAP(-), and ours in full-length Replica (Room0) sequence, given ground truth (GT) poses without depth supervision. </h3>
            <h3 align="center">(-) denotes that we make modifications to the original implementations by eliminating the back-propagation of the gradient from depth supervision. </h3>
              
              <!-- Images -->
              <div class="container"> 
                <div align="center" style="margin-top:80px;" style="margin-bottom:120px;">
                  <img style='height: auto; width: 100%; object-fit: contain'
                        src="show1.png" alt="show1">
              </div>
              </div>
              <br>
              <div class="container"> 
                <div align="center" style="margin-top:80px;" style="margin-bottom:120px;">
                  <img style='height: auto; width: 100%; object-fit: contain'
                        src="show2.png" alt="show2">
              </div>
              </div>
              <br>
    </section>

    <br>
    <br>
    <br>

      <section class="section" id="BibTeX citation">
        <div class="container content">
          <h2 class="title">BibTeX</h2>
          <pre><code>
@inproceedings{fmaphua23,
  author = {T, Hua. H, Bai. Z, Cao. and L, Wang.},
  title = {{FMapping}: Factorized Efficient Neural Field Mapping for Real-Time Dense RGB SLAM},
  year = {2023},
  type = {arXiv}
}
          </code></pre>
        </div>
      </section>

  </body>
</html>

<script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
<script src="./static/js/bulma-carousel.min.js"></script>
<script src="./static/js/bulma-slider.min.js"></script>
<script src="./static/js/index.js"></script>  

<script src="./static/js/magnifier.js"></script>
<script> imageZoom("reference", ["zoomed-imap", "zoomed-nice", "zoomed-eslam" ], 7); </script>
<script> imageZoom("reference_mesh", ["zoomed-imap_mesh", "zoomed-nice_mesh", "zoomed-eslam_mesh" ], 7); </script>
